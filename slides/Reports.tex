%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluating Reports}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
    \frametitle{Outline}
    \begin{columns}[t]
        \begin{column}{.5\textwidth}
            \tableofcontents[sections={1-9},currentsection]
        \end{column}
        \begin{column}{.5\textwidth}
            \tableofcontents[sections={10-18},currentsection]
        \end{column}
    \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{What is this about?}
   \begin{question}[Questions]
   	  \begin{itemize}
         \item Is there a way to get benchmarking information?
         \item When I want to write a publication, which software(s) version(s) have I been using?
      \end{itemize}
   \end{question}
   \docs[Objectives]{\begin{enumerate}
                      \item Learn the implications and limitations of benchmarks.
                      \item Learning how to generate and interprate reports with \texttt{Snakemake}.
                     \end{enumerate}}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Benchmarking}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{What is ``Benchmarking'' in Computer Science?}
  \lhref{https://en.wikipedia.org/wiki/Benchmarking}{Benchmarking} may mean a number of things:
  \begin{itemize}[<+->]
   \item assessing software quality
   \item assessing software completeness (all the features we want?)
   \item assessing software usability
   \item \ldots
  \end{itemize}
  \pause
  \docs{What is most commonly meant: Getting performance and scalability markers.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Generating Benchmarks}
  Similar to crating a logfile, we are provided with a \altverb{benchmark}-directive, which can point to a bechmarking file:
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
    ...
    log:
        "logs/bwa_mem/{sample}.log"
    benchmark:
        "benchmarks/{sample}.bwa.benchmark.txt"
    ...
  \end{lstlisting} 
  \docs{\texttt{Snakemake} will measure the wall clock time and memory usage (in MiB) and store it in the file in tab-delimited format.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Repeating Benchmarks}
  \vfill
  \begin{exampleblock}{Repeated benchmarks}
   It is possible to repeat a benchmark multiple times in order to get a sense for the variability of the measurements. This can be done by annotating the benchmark file, e.\,g., with \altverb{repeat("benchmarks/\{sample\}.bwa.benchmark.txt", 3)}. \texttt{Snakemake} can be told to run the job three times. The repeated measurements occur as subsequent lines in the tab-delimited benchmark file.
  \end{exampleblock}
  \vfill
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{``Proper'' Benchmarking}
  A good estimate of a software's scalability takes into account:
  \begin{itemize}[<+->]
   \item running with different degrees of parallelization, e.\,g. 1-n threads
   \item not using toy inputs, but real data, possibly different real data
   \item avoiding I/O issues (common with alignment programs)
  \end{itemize}
  \pause
  \warning{We conclude: \texttt{Snakemake}'s benchmarking capabilities are limited!}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reporting}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{\texttt{Snakemake} Reports}
  Asking \texttt{Snakemake} for a report on a completed workflow is as easy as:
  \begin{lstlisting}[language=Bash, style=Shell]
$ snakemake --report
  \end{lstlisting}
  This will generate a file called ``\altverb{report.html}'', which you can visualize with a browser.
  \pause
  %TODO adjust, once working
  \begin{alertblock}{Viewing the Report}
   Due to a bug on \mogon: Copy the file to your computer and visualize it in your browser!
  \end{alertblock}
\end{frame} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{\texttt{Snakemake} Reports and Cluster Jobs}
  \begin{alertblock}{Why reports about Cluster Jobs can be misleading.}
    When reporting about a cluster or cloud job, \texttt{Snakemake} sheperd job on the login-node will measure the wall time from submit time to the finish time, not the executing job(s).\newline
    This means: Times can be greatly exegerated!
  \end{alertblock}
\end{frame} 

