%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluating Reports}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
    \frametitle{Outline}
    \begin{columns}[t]
        \begin{column}{.5\textwidth}
            \tableofcontents[sections={1-9},currentsection]
        \end{column}
        \begin{column}{.5\textwidth}
            \tableofcontents[sections={10-18},currentsection]
        \end{column}
    \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{What is this about?}
   \question[Questions]{\begin{itemize}
                         \item Is there a way to get benchmarking information?
                         \item When I want to write a publication, which software(s) version(s) have I been using?
                        \end{itemize}
                       }
   \docs[Objectives]{\begin{enumerate}
                      \item Learning how to generate and interprate reports with \texttt{Snakemake}.
                     \end{enumerate}}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Benchmarking}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{What is ``Benchmarking'' in Computer Science?}
  \lhref{https://en.wikipedia.org/wiki/Benchmarking}{Benchmarking} may mean a number of things:
  \begin{itemize}[<+->]
   \item assessing software quality
   \item assessing software completeness (all the features we want?)
   \item assessing software usability
   \item \ldots
  \end{itemize}
  \pause
  \docs{What is most commonly meant: Getting performance and scalability markers.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Generating Benchmarks}
  Similar to crating a logfile, we are provided with a \altverb{benchmark}-directive, which can point to a bechmarking file:
  \begin{lstlisting}[language=Python,style=Python]
rule bwa_map:
    ...
    log:
        "logs/bwa_mem/{sample}.log"
    benchmark:
        "benchmarks/{sample}.bwa.benchmark.txt"
    ...
  \end{lstlisting} 
  \docs{\texttt{Snakemake} will measure the wall clock time and memory usage (in MiB) and store it in the file in tab-delimited format.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Repeating Benchmarks}
  \vfill
  \begin{exampleblock}{Repeated benchmarks}
   It is possible to repeat a benchmark multiple times in order to get a sense for the variability of the measurements. This can be done by annotating the benchmark file, e.\,g., with \altverb{repeat("benchmarks/{sample}.bwa.benchmark.txt", 3)}. \texttt{Snakemake} can be told to run the job three times. The repeated measurements occur as subsequent lines in the tab-delimited benchmark file.
  \end{exampleblock}
  \vill
\end{frame}  


